{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c84ad7-9fe9-4395-8f58-8da283b95747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import datetime as dt\n",
    "import json\n",
    "import pymongo\n",
    "from plotting_streamlit import data_import, scraper, get_db_client, data_export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3ffa0-5926-4fc1-a28a-2d08514bf63a",
   "metadata": {},
   "source": [
    "### List of mumsnet urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6d43bd-616b-487f-9a52-434664ab1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [#'https://www.mumsnet.com/talk/am_i_being_unreasonable/4676538-if-you-like-wordle-plusword-is-even-better-thread-4?page=',\n",
    "            #'https://www.mumsnet.com/talk/_chat/4714295-plusword-new-thread-1?page=',\n",
    "            'https://www.mumsnet.com/talk/_chat/4765702-plusword-new-thread-2?page=']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3775fa-27b9-47a7-ac80-27678ae9a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url, max_pages, whole_post_list):\n",
    "    \n",
    "    # Increments through every page on website until it runs out for hits max_pages\n",
    "    for page_number in range(max_pages):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # gets request via bs4\n",
    "            r = requests.get(url + str(page_number))\n",
    "            soup = BeautifulSoup(r.content)\n",
    "            \n",
    "            # Finds original post on each page and splits it into metadata and post text\n",
    "            original_post = soup.find_all('div', class_= 'p-4 pb-1 pt-2.5 lg:py-2.5 mt-2.5 lg:mt-1.5 border-t border-b sm:border sm:rounded border-mumsnet-forest-border bg-mumsnet-forest dark:bg-mumsnet-forest-dark')\n",
    "            original_post_paragraphs=original_post[0].find_all('p')\n",
    "            \n",
    "            # converts to list\n",
    "            meta_data = original_post_paragraphs[0].getText().split()\n",
    "            \n",
    "            # removes fullstop in position 1\n",
    "            meta_data.pop(1)\n",
    "            \n",
    "            # converts text to list and then joins items together\n",
    "            post_text = original_post_paragraphs[1].getText().split()\n",
    "            post_text =' '.join(post_text)\n",
    "            \n",
    "            # Adds OP metadata and text together and adds together for OP on every page\n",
    "            meta_data.append(post_text)\n",
    "            whole_post = meta_data\n",
    "            whole_post_list.append(whole_post)\n",
    "            \n",
    "            # finds all non-OP post on page and gets data\n",
    "            posts= soup.find_all('div', class_=['lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 overflow-x-hidden bg-white dark:bg-gray-800 border-gray-200',\n",
    "                                                'lg:py-2.5 pt-2.5 pb-1 p-4 border-t border-b sm:border sm:rounded mt-1.5 overflow-x-hidden bg-mumsnet-forest dark:bg-mumsnet-forest-dark border-mumsnet-forest-border'])\n",
    "            for post in posts:\n",
    "                post_info = post.getText().split()\n",
    "                \n",
    "                #first 4 items are meta data\n",
    "                meta_data = post_info[:4]\n",
    "                \n",
    "                #removes uneeded full stop\n",
    "                meta_data.pop(1)\n",
    "                \n",
    "               # joins post text together\n",
    "                post_text = post_info[4:]\n",
    "                post_text = ' '.join(post_text)\n",
    "                \n",
    "                \n",
    "                # appends metadata and text together and adds to list\n",
    "                meta_data.append(post_text)\n",
    "                whole_post = meta_data\n",
    "                whole_post_list.append(whole_post)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return whole_post_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2c62c-21ae-41dd-abfe-e31a4cc01b08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scraper initialization and df generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ccb6c5-607b-4685-ba22-4739129f9c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunbird24</td>\n",
       "      <td>18/03/2023</td>\n",
       "      <td>07:29</td>\n",
       "      <td>Previous thread: www.mumsnet.com/talk/_chat/47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bruffin</td>\n",
       "      <td>19/03/2023</td>\n",
       "      <td>19:16</td>\n",
       "      <td>marking my spot Add message Save Share Report ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MarmiteWine</td>\n",
       "      <td>19/03/2023</td>\n",
       "      <td>20:38</td>\n",
       "      <td>00:45 today Add message Save Share Report Book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drywhitefruitycidergin</td>\n",
       "      <td>20/03/2023</td>\n",
       "      <td>00:54</td>\n",
       "      <td>⏱️ I just completed PlusWord in 02:47 www.tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drywhitefruitycidergin</td>\n",
       "      <td>20/03/2023</td>\n",
       "      <td>00:55</td>\n",
       "      <td>*thread ffs - that's why I'm so slow at pw too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>sanityisamyth</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>05:44</td>\n",
       "      <td>⏱️ I just completed PlusWord in 01:03 www.tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Drywhitefruitycidergin</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>06:24</td>\n",
       "      <td>⏱️ I just completed PlusWord in 04:04 www.tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>DadDadDad</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>07:04</td>\n",
       "      <td>1:27 for me today. Add message Save Share Repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Madcats</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>09:40</td>\n",
       "      <td>It took me a while to understand the answer to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>PlusWordImogen</td>\n",
       "      <td>21/03/2023</td>\n",
       "      <td>10:50</td>\n",
       "      <td>Hi all! I work on the Puzzles team at the Tele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user        date   time  \\\n",
       "0                  Sunbird24  18/03/2023  07:29   \n",
       "1                    bruffin  19/03/2023  19:16   \n",
       "2                MarmiteWine  19/03/2023  20:38   \n",
       "3     Drywhitefruitycidergin  20/03/2023  00:54   \n",
       "4     Drywhitefruitycidergin  20/03/2023  00:55   \n",
       "...                      ...         ...    ...   \n",
       "1053           sanityisamyth  21/03/2023  05:44   \n",
       "1054  Drywhitefruitycidergin  21/03/2023  06:24   \n",
       "1055               DadDadDad  21/03/2023  07:04   \n",
       "1056                 Madcats  21/03/2023  09:40   \n",
       "1057          PlusWordImogen  21/03/2023  10:50   \n",
       "\n",
       "                                                   text  \n",
       "0     Previous thread: www.mumsnet.com/talk/_chat/47...  \n",
       "1     marking my spot Add message Save Share Report ...  \n",
       "2     00:45 today Add message Save Share Report Book...  \n",
       "3     ⏱️ I just completed PlusWord in 02:47 www.tele...  \n",
       "4     *thread ffs - that's why I'm so slow at pw too...  \n",
       "...                                                 ...  \n",
       "1053  ⏱️ I just completed PlusWord in 01:03 www.tele...  \n",
       "1054  ⏱️ I just completed PlusWord in 04:04 www.tele...  \n",
       "1055  1:27 for me today. Add message Save Share Repo...  \n",
       "1056  It took me a while to understand the answer to...  \n",
       "1057  Hi all! I work on the Puzzles team at the Tele...  \n",
       "\n",
       "[1058 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_post_list=[]\n",
    "\n",
    "# maxiumum number of pages in thread\n",
    "max_pages = 41\n",
    "\n",
    "for url in url_list:\n",
    "\n",
    "    whole_post_list = scraper(url, max_pages, whole_post_list)\n",
    "            \n",
    "df = pd.DataFrame(whole_post_list, columns=['user', 'date', 'time', 'text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7104a-9f1b-4b66-987f-4bc4a19aff4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Converts 'Today' and 'Yesterday to date values, creates and sorts by timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5584b88b-4419-47cb-9731-d25d46ef190d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['date'] = df['date'].str.replace('Yesterday', dt.datetime.strftime((dt.datetime.today() - dt.timedelta(days=1)), '%d/%m/%Y'))\n",
    "df['date'] = df['date'].str.replace('Today', dt.datetime.strftime(dt.datetime.today(), '%d/%m/%Y'))\n",
    "df['load_ts'] = df['date'] + ' ' + (df['time']+':00')\n",
    "df['load_ts'] = df['load_ts'] + '.000'\n",
    "df['load_ts'] = pd.to_datetime(df['load_ts'], format='%d/%m/%Y %H:%M:%S.%f')\n",
    "df = df.sort_values(by=['load_ts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4216210-d8d4-4408-b017-32bdbf1fd74e",
   "metadata": {},
   "source": [
    "### Extracts times from text and adds 00: to allow it to handle hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e2efb6-5742-41ba-8b3e-76e9bd47755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] =df['text'].str.extract(r'(\\d*\\d:\\d\\d)')\n",
    "df = df.dropna(subset='text')\n",
    "df = df.copy()\n",
    "df['text'] =df['text'].str.replace(r'(^\\d:\\d\\d)', r'0\\1', regex=True)\n",
    "df['text'] = '00:' + df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcc181-ee50-459a-b718-16b82b91c9b8",
   "metadata": {},
   "source": [
    "### Drops duplicate entries for users on same date, drops columns and renames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b789493-e469-4e54-a415-30f581528120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df= df.drop_duplicates(subset=['user', 'date'])\n",
    "df = df.drop(columns=['date', 'time'])\n",
    "df = df.rename(columns={'text' : 'time'})\n",
    "df = df[['load_ts', 'time', 'user']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4af34-cb43-48ff-a097-f0d8d1aaee3a",
   "metadata": {},
   "source": [
    "### Loads in db data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e9e73-1829-4ed3-9580-4295c1d96d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mums = data_import('Mumsnet_Times')\n",
    "df_mums['load_ts'] = pd.to_datetime(df_mums['load_ts'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "df_mums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b38aed0-857a-4727-bab9-5aa469edda3f",
   "metadata": {},
   "source": [
    "### Filters out rows that are already in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "117bb3d3-4cf8-48a1-ad44-8b79c5f96e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['load_ts', 'user'])\n",
    "df_mums = df_mums.set_index(['load_ts', 'user'])\n",
    "df = df[~df.index.isin(df_mums.index)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ef122-dfa6-409e-ad2e-e5046fae9fe3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Formats df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62a2fb5-493b-408c-a51a-9c96d9628645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['load_ts'] = df['load_ts'].astype('str')\n",
    "df['load_ts'] = df['load_ts'] +'.000'\n",
    "df = df[['load_ts', 'time', 'user']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc618f-35b2-4b48-8646-b8a99230901a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_ts</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [load_ts, time, user]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not dataframe.empty:\n",
    "    data_export(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceabc69-c1a5-4660-9e3c-3560d1b6813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
